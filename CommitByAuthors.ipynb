{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Commits Summary by Authors and Repos for a range of Weeks\n",
    "This code consolidate the contributors (with similar name using [Cosin Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)) and generate the summary and graph of commits/files/changes for a range of weeks and the set of repos.\n",
    "<br/>The code relied on [git-quick-stats](https://github.com/amiller/git-quick-stats) to generate the git log output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "def parseNumber(key, return_pos, line):\n",
    "    section = list(filter(len, line.split(' ')))\n",
    "    #print(key, section, return_pos, line)\n",
    "    if key == section[0]:\n",
    "        return int(section[return_pos])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git command template for git-quick-stats \n",
    "gitLogCommandTemplate = 'cd {path} && export _GIT_SINCE=\"{from_date}\" && export _GIT_UNTIL=\"{to_date}\" && git-quick-stats -T > {output_filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "# Replace the sourcePath with your local repo path\n",
    "sourcePath = '{set-your-local-repo-path-here}/'\n",
    "repos = [f for f in glob.glob(sourcePath + \"**/\", recursive=False)]\n",
    "print(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Model\n",
    "gitInfo = Dict[str, List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "def Run(weeks: int) -> gitInfo:\n",
    "    info = {'repo': [], 'author':[], 'dateending':[], 'insertions':[], 'deletions':[], 'files':[], 'commits':[], 'lineschanged':[]}\n",
    "    for repo in repos:\n",
    "        repoName = repo.strip().split('/')[-2:-1][0]\n",
    "        cmd = gitLogCommandTemplate.replace('{path}', repo)\n",
    "        for week in range(1,weeks+1):\n",
    "            # map\n",
    "            from_date = (datetime.date.today() - datetime.timedelta(days=week*7)).isoformat()\n",
    "            to_date = (datetime.date.today() - datetime.timedelta(days=(week-1)*7)).isoformat()\n",
    "            output_filename = '{0}_{1}.txt'.format(from_date, to_date)\n",
    "            cmdw = cmd.replace('{from_date}', from_date)\n",
    "            cmdw = cmdw.replace('{to_date}', to_date)\n",
    "            cmdw = cmdw.replace('{output_filename}', output_filename)\n",
    "            exit_code = os.system(cmdw)\n",
    "            #print(exit_code)\n",
    "            output_filename = repo + output_filename\n",
    "\n",
    "            # reduce\n",
    "            with open(output_filename) as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) > 5:\n",
    "                    line_pos = 2\n",
    "                    while line_pos + 8 < len(lines):\n",
    "                        author = lines[line_pos].strip().replace(':','')\n",
    "                        if author.startswith('total'):\n",
    "                            break\n",
    "                        elif len(author) == 0 or author.startswith('last commit') or author.startswith('first commit'):\n",
    "                            line_pos += 1\n",
    "                            continue\n",
    "                        info['repo'].append(repoName)\n",
    "                        info['author'].append(author)\n",
    "                        info['dateending'].append(to_date)\n",
    "\n",
    "                        line_pos += 1\n",
    "                        if lines[line_pos+1].strip().startswith('insertions'):\n",
    "                            info['insertions'].append(parseNumber('insertions', 1, lines[line_pos].strip().replace(':','')))\n",
    "                        else:\n",
    "                            info['insertions'].append(0)\n",
    "\n",
    "                        line_pos += 1\n",
    "                        if lines[line_pos].strip().startswith('deletions'):\n",
    "                            info['deletions'].append(parseNumber('deletions', 1, lines[line_pos].strip().replace(':','')))\n",
    "                        else:\n",
    "                            info['deletions'].append(0)\n",
    "\n",
    "                        line_pos += 1\n",
    "                        if lines[line_pos].strip().startswith('files'):\n",
    "                            info['files'].append(parseNumber('files', 1, lines[line_pos].strip().replace(':','')))\n",
    "                        else:\n",
    "                            info['files'].append(0)\n",
    "\n",
    "                        line_pos += 1\n",
    "                        if lines[line_pos].strip().startswith('commits'):\n",
    "                            info['commits'].append(parseNumber('commits', 1, lines[line_pos].strip().replace(':','')))\n",
    "                        else:\n",
    "                            info['commits'].append(0)\n",
    "\n",
    "                        line_pos += 1\n",
    "                        if lines[line_pos].strip().startswith('lines'):\n",
    "                            info['lineschanged'].append(parseNumber('lines', 2, lines[line_pos].strip().replace(':','')))\n",
    "                        else:\n",
    "                            info['lineschanged'].append(0)\n",
    "\n",
    "                        line_pos += 1\n",
    "                        \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver, get data for past 8 weeks\n",
    "data = Run(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate the author with similar names, I am using consine similarity here \n",
    "# The cos_sim is a k x n matrix where the diagonal elements are 1.\n",
    "\n",
    "authors = sorted(list(set(data['author'])))\n",
    "vectorizer = CountVectorizer().fit_transform(authors)\n",
    "vectors = vectorizer.toarray()\n",
    "cos_sim = cosine_similarity(vectors)\n",
    "\n",
    "# Uncomment below to view the content\n",
    "#print(authors)\n",
    "#cos_sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now consolidate author in the info data model \n",
    "# I use cosine similatrity score of 60 as the threshold to be consider as \"same author\"\n",
    "similarity_threshold= 0.6\n",
    "\n",
    "author_table={}\n",
    "skipList=set()\n",
    "for i in range(0, len(cos_sim)):\n",
    "    if i not in skipList:\n",
    "        author_table[authors[i]] = authors[i]\n",
    "        skipList.add(i)\n",
    "        #print(skipList)\n",
    "        for j in range(i+1, len(cos_sim)):\n",
    "            if cos_sim[j][i] >= similarity_threshold:\n",
    "                author_table[authors[j]] = authors[i]\n",
    "                skipList.add(j)\n",
    "#print(author_table)\n",
    "for i in range(0, len(data['author'])):\n",
    "    data['author'][i] = author_table[data['author'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "commits_grp = df.groupby(['author','dateending'])[['author','dateending','commits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col, row = 0, 0\n",
    "fig, axes = plt.subplots(nrows=6, ncols=2, figsize=(22,25))\n",
    "for a in set(author_table.values()):\n",
    "    a1 = commits_grp.filter(lambda x: (x['author'] == a).any()).groupby(['dateending']).sum()\n",
    "    a1plot = a1.plot(ax=axes[row][col], title=a, marker='o')\n",
    "    _ = a1plot.set(xlabel='Date', ylabel='Commits');\n",
    "    col += 1\n",
    "    if col == 2:\n",
    "        col = 0\n",
    "        row += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data frame to CSV\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('output.csv')\n",
    "\n",
    "# # Group by commits and save to CSV\n",
    "# filterby = 'commits'\n",
    "\n",
    "# df1 = df.groupby(['repo', 'dateending', 'author'], as_index=False)[filterby].sum().pivot('repo', 'author','dateending').fillna(0)\n",
    "# df1.to_csv('output-repo-filter-commits.csv')\n",
    "\n",
    "# df2 = df.groupby(['dateending', 'author'], as_index=False)[filterby].sum().pivot('author','dateending').fillna(0)\n",
    "# df2.to_csv('output-filter-commits.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
